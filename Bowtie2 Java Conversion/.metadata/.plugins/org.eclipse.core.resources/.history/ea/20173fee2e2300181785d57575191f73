package com.uwb.bt2j.indexer.blockwise;

import org.omg.CORBA_2_3.portable.OutputStream;

import com.uwb.bt2j.indexer.RandomSource;
import com.uwb.bt2j.indexer.types.ELList;
import com.uwb.bt2j.indexer.types.EList;

import javafx.util.Pair;

public class KarkkainenBlockwiseSA extends InorderBlockwiseSA{
	
	class BinarySortingParam {
		String t;
		EList<Long> sampleSuffs;
		EList<Long> bucketSzs;
		EList<Long> bucketReps;
		int begin;
		int end;
	}
	
	private EList<Long> _sampleSuffs;
	private int _nthreads;
	private long _itrBucketIdx;
	private long _cur;
	private int _dcV;
	private boolean _built;
	private RandomSource _randomSrc;
	private String _base_fname;
	private boolean _bigEndian;
	//private EList<Thread>
	private EList<Pair<KarkkainenBlockwiseSA, Integer>> _tParams;
	private ELList<Long> _itrBuckets;
	private boolean _done;

	public KarkkainenBlockwiseSA(String __text, long __bucketSz, int __nthreads, int __dcV, int __seed, boolean __sanityCheck, boolean __passMemExc,
			boolean __verbose, String base_fname, OutputStream __logger) {
		super(__text, __bucketSz, __sanityCheck, __passMemExc, __verbose, __logger);
		_sampleSuffs = new EList(2);
		_nthreads = __nthreads;
		_itrBucketIdx = 0;
		_cur = 0;
		_dcV = __dcV;
		_dc = 2;
		_built = false;
		_base_fname = base_fname;
		_bigEndian = false;
	}
	
	public static int simulateAllocs(String text, int bucketSz) {
		 int len = text.length();
	        // _sampleSuffs and _itrBucket are in memory at the peak
	        int bsz = bucketSz;
	        int sssz = (int) (len / Long.max(bucketSz-1, 1));
	        long[] tmp = new long[bsz + sssz + (1024 * 1024 /*out of caution*/)];
	        return bsz;
	}

	public long nextSuffix() {
		// Launch threads if not
				if(this._nthreads > 1) {
		
					if(_threads.size() == 0) {
		                _done = _sampleSuffs.size() + 1; 
		                for (int i = 0; i < _sampleSuffs.size() + 1; i++) {
		                    _done.get()[i] = false;
		                }
						_itrBuckets.resize(this._nthreads);
						_tparams.resize(this._nthreads);
						for(int tid = 0; tid < this._nthreads; tid++) {
							_tparams[tid].first = this;
							_tparams[tid].second = tid;
							_threads.push_back(new tthread::thread(nextBlock_Worker, (void*)&_tparams[tid]));
						}
					}
				}
				if(this._itrPushedBackSuffix != OFF_MASK) {
					TIndexOffU tmp = this._itrPushedBackSuffix;
					this._itrPushedBackSuffix = OFF_MASK;
					return tmp;
				}
				while(this._itrBucketPos >= this._itrBucket.size() ||
				      this._itrBucket.size() == 0)
				{
					if(!hasMoreBlocks()) {
						throw out_of_range("No more suffixes");
					}
					if(this._nthreads == 1) {
						nextBlock((int)_cur);
						_cur++;
					} else {
						while(!_done.get()[this._itrBucketIdx]) {
							SLEEP(1);
						}
						// Read suffixes from a file
						std::ostringstream number; number << this._itrBucketIdx;
						const string fname = _base_fname + "." + number.str() + ".sa";
						ifstream sa_file(fname.c_str(), ios::binary);
						if(!sa_file.good()) {
							cerr << "Could not open file for reading a suffix array: \"" << fname << "\"" << endl;
							throw 1;
						}
						int numSAs = readU<TIndexOffU>(sa_file, _bigEndian);
						this._itrBucket.resizeExact(numSAs);
						for(int i = 0; i < numSAs; i++) {
							this._itrBucket[i] = readU<TIndexOffU>(sa_file, _bigEndian);
						}
						sa_file.close();
						std::remove(fname.c_str());
					}
					this._itrBucketIdx++;
					this._itrBucketPos = 0;
				}
				return this._itrBucket[this._itrBucketPos++];
	}
	
	public int dcV() {
		return _dcV;
	}
	
	public static void BinarySorting_worker() {
		 BinarySortingParam<TStr>* param = (BinarySortingParam<TStr>*)vp;
		    const TStr& t = *(param->t);
		    size_t len = t.length();
		    const EList<TIndexOffU>& sampleSuffs = *(param->sampleSuffs);
		    EList<TIndexOffU>& bucketSzs = param->bucketSzs;
		    EList<TIndexOffU>& bucketReps = param->bucketReps;
		    ASSERT_ONLY(size_t numBuckets = bucketSzs.size());
		    size_t begin = param->begin;
		    size_t end = param->end;
		    // Iterate through every suffix in the text, determine which
		    // bucket it falls into by doing a binary search across the
		    // sorted list of samples, and increment a counter associated
		    // with that bucket.  Also, keep one representative for each
		    // bucket so that we can split it later.  We loop in ten
		    // stretches so that we can print out a helpful progress
		    // message.  (This step can take a long time.)
		    for(TIndexOffU i = (TIndexOffU)begin; i < end && i < len; i++) {
		        TIndexOffU r = binarySASearch(t, i, sampleSuffs);
		        if(r == std::numeric_limits<TIndexOffU>::max()) continue; // r was one of the samples
		        assert_lt(r, numBuckets);
		        bucketSzs[r]++;
		        assert_lt(bucketSzs[r], len);
		        if(bucketReps[r] == OFF_MASK || (i & 100) == 0) {
		            bucketReps[r] = i; // clobbers previous one, but that's OK
		        }
		    }
	}
	
	public static void nextBlockWorker() {
		pair<KarkkainenBlockwiseSA*, int> param = *(pair<KarkkainenBlockwiseSA*, int>*)vp;
        KarkkainenBlockwiseSA* sa = param.first;
        int tid = param.second;
        while(true) {
            size_t cur = 0;
            {
                ThreadSafe ts(sa->_mutex);
                cur = sa->_cur;
                if(cur > sa->_sampleSuffs.size()) break;
                sa->_cur++;
            }
            sa->nextBlock((int)cur, tid);
            // Write suffixes into a file
            std::ostringstream number; number << cur;
            const string fname = sa->_base_fname + "." + number.str() + ".sa";
            ofstream sa_file(fname.c_str(), ios::binary);
            if(!sa_file.good()) {
                cerr << "Could not open file for writing a reference graph: \"" << fname << "\"" << endl;
                throw 1;
            }
            const EList<TIndexOffU>& bucket = sa->_itrBuckets[tid];
            writeU<TIndexOffU>(sa_file, (TIndexOffU)bucket.size(), sa->_bigEndian);
            for(size_t i = 0; i < bucket.size(); i++) {
                writeU<TIndexOffU>(sa_file, bucket[i], sa->_bigEndian);
            }
            sa_file.close();
            sa->_itrBuckets[tid].clear();
            sa->_done.get()[cur] = true;
        }
	}
	
	protected void reset() {
		if(!_built) {
			build();
		}
		_cur = 0;
	}
	
	protected boolean isReset() {
		return _cur == 0;
	}
	
	private void build() {
		// Calculate difference-cover sample
        if(_dcV != 0) {
            _dc.init(new TDC(this->text(), _dcV, this->verbose(), this->sanityCheck()));
            _dc.get()->build(this->_nthreads);
        }
        // Calculate sample suffixes
        if(this->bucketSz() <= this->text().length()) {
            VMSG_NL("Building samples");
            buildSamples();
        } else {
            VMSG_NL("Skipping building samples since text length " <<
                    this->text().length() << " is less than bucket size: " <<
                    this->bucketSz());
        }
        _built = true;
	}
	
	private void buildSamples() {
		const TStr& t = this->text();
	    TIndexOffU bsz = this->bucketSz()-1; // subtract 1 to leave room for sample
	    size_t len = this->text().length();
	    // Prepare _sampleSuffs array
	    _sampleSuffs.clear();
	    TIndexOffU numSamples = (TIndexOffU)((len/bsz)+1)<<1; // ~len/bsz x 2
	    assert_gt(numSamples, 0);
	    VMSG_NL("Reserving space for " << numSamples << " sample suffixes");
	    if(this->_passMemExc) {
	        _sampleSuffs.resizeExact(numSamples);
	        // Randomly generate samples.  Allow duplicates for now.
	        VMSG_NL("Generating random suffixes");
	        for(size_t i = 0; i < numSamples; i++) {
	#ifdef BOWTIE_64BIT_INDEX
	            _sampleSuffs[i] = (TIndexOffU)(_randomSrc.nextU64() % len);
	#else
	            _sampleSuffs[i] = (TIndexOffU)(_randomSrc.nextU32() % len);
	#endif
	        }
	    } else {
	        try {
	            _sampleSuffs.resizeExact(numSamples);
	            // Randomly generate samples.  Allow duplicates for now.
	            VMSG_NL("Generating random suffixes");
	            for(size_t i = 0; i < numSamples; i++) {
	#ifdef BOWTIE_64BIT_INDEX
	                _sampleSuffs[i] = (TIndexOffU)(_randomSrc.nextU64() % len);
	#else
	                _sampleSuffs[i] = (TIndexOffU)(_randomSrc.nextU32() % len);
	#endif
	            }
	        } catch(bad_alloc &e) {
	            if(this->_passMemExc) {
	                throw e; // rethrow immediately
	            } else {
	                cerr << "Could not allocate sample suffix container of " << (numSamples * OFF_SIZE) << " bytes." << endl
	                << "Please try using a smaller number of blocks by specifying a larger --bmax or" << endl
	                << "a smaller --bmaxdivn" << endl;
	                throw 1;
	            }
	        }
	    }
	    // Remove duplicates; very important to do this before the call to
	    // mkeyQSortSuf so that it doesn't try to calculate lexicographical
	    // relationships between very long, identical strings, which takes
	    // an extremely long time in general, and causes the stack to grow
	    // linearly with the size of the input
	    {
	        Timer timer(cout, "QSorting sample offsets, eliminating duplicates time: ", this->verbose());
	        VMSG_NL("QSorting " << _sampleSuffs.size() << " sample offsets, eliminating duplicates");
	        _sampleSuffs.sort();
	        size_t sslen = _sampleSuffs.size();
	        for(size_t i = 0; i < sslen-1; i++) {
	            if(_sampleSuffs[i] == _sampleSuffs[i+1]) {
	                _sampleSuffs.erase(i--);
	                sslen--;
	            }
	        }
	    }
	    // Multikey quicksort the samples
	    {
	        Timer timer(cout, "  Multikey QSorting samples time: ", this->verbose());
	        VMSG_NL("Multikey QSorting " << _sampleSuffs.size() << " samples");
	        this->qsort(_sampleSuffs);
	    }
	    // Calculate bucket sizes
	    VMSG_NL("Calculating bucket sizes");
	    int limit = 5;
	    // Iterate until all buckets are less than
	    while(--limit >= 0) {
	        TIndexOffU numBuckets = (TIndexOffU)_sampleSuffs.size()+1;
	#ifdef WITH_TBB
		tbb::task_group tbb_grp;
	#else
	        AutoArray<tthread::thread*> threads(this->_nthreads);
	#endif
	        EList<BinarySortingParam<TStr> > tparams;
	        tparams.resize(this->_nthreads);
	        for(int tid = 0; tid < this->_nthreads; tid++) {
	            // Calculate bucket sizes by doing a binary search for each
	            // suffix and noting where it lands
	            try {
	                // Allocate and initialize containers for holding bucket
	                // sizes and representatives.
	                tparams[tid].bucketSzs.resizeExact(numBuckets);
	                tparams[tid].bucketReps.resizeExact(numBuckets);
	                tparams[tid].bucketSzs.fillZero();
	                tparams[tid].bucketReps.fill(OFF_MASK);
	            } catch(bad_alloc &e) {
	                if(this->_passMemExc) {
	                    throw e; // rethrow immediately
	                } else {
	                    cerr << "Could not allocate sizes, representatives (" << ((numBuckets*8)>>10) << " KB) for blocks." << endl
	                    << "Please try using a smaller number of blocks by specifying a larger --bmax or a" << endl
	                    << "smaller --bmaxdivn." << endl;
	                    throw 1;
	                }
	            }
	            tparams[tid].t = &t;
	            tparams[tid].sampleSuffs = &_sampleSuffs;
	            tparams[tid].begin = (tid == 0 ? 0 : len / this->_nthreads * tid);
	            tparams[tid].end = (tid + 1 == this->_nthreads ? len : len / this->_nthreads * (tid + 1));
	            if(this->_nthreads == 1) {
	                BinarySorting_worker<TStr>((void*)&tparams[tid]);
	            } else {
	#ifdef WITH_TBB
	        			tbb_grp.run(BinarySorting_worker<TStr>(((void*)&tparams[tid])));
			        }
	        }
	      	tbb_grp.wait();
	#else
	             threads[tid] = new tthread::thread(BinarySorting_worker<TStr>, (void*)&tparams[tid]);
	            }
	        }
	        
	        if(this->_nthreads > 1) {
	            for (int tid = 0; tid < this->_nthreads; tid++) {
	                threads[tid]->join();
	            }
	        }
	#endif
	        
	        EList<TIndexOffU>& bucketSzs = tparams[0].bucketSzs;
	        EList<TIndexOffU>& bucketReps = tparams[0].bucketReps;
	        for(int tid = 1; tid < this->_nthreads; tid++) {
	            for(size_t j = 0; j < numBuckets; j++) {
	                bucketSzs[j] += tparams[tid].bucketSzs[j];
	                if(bucketReps[j] == OFF_MASK) {
	                    bucketReps[j] = tparams[tid].bucketReps[j];
	                }
	            }
	        }
	        // Check for large buckets and mergeable pairs of small buckets
	        // and split/merge as necessary
	        TIndexOff added = 0;
	        TIndexOff merged = 0;
	        assert_eq(bucketSzs.size(), numBuckets);
	        assert_eq(bucketReps.size(), numBuckets);
	        {
	            Timer timer(cout, "  Splitting and merging time: ", this->verbose());
	            VMSG_NL("Splitting and merging");
	            for(TIndexOffU i = 0; i < numBuckets; i++) {
	                TIndexOffU mergedSz = bsz + 1;
	                assert(bucketSzs[(size_t)i] == 0 || bucketReps[(size_t)i] != OFF_MASK);
	                if(i < numBuckets-1) {
	                    mergedSz = bucketSzs[(size_t)i] + bucketSzs[(size_t)i+1] + 1;
	                }
	                // Merge?
	                if(mergedSz <= bsz) {
	                    bucketSzs[(size_t)i+1] += (bucketSzs[(size_t)i]+1);
	                    // The following may look strange, but it's necessary
	                    // to ensure that the merged bucket has a representative
	                    bucketReps[(size_t)i+1] = _sampleSuffs[(size_t)i+added];
	                    _sampleSuffs.erase((size_t)i+added);
	                    bucketSzs.erase((size_t)i);
	                    bucketReps.erase((size_t)i);
	                    i--; // might go to -1 but ++ will overflow back to 0
	                    numBuckets--;
	                    merged++;
	                    assert_eq(numBuckets, _sampleSuffs.size()+1-added);
	                    assert_eq(numBuckets, bucketSzs.size());
	                }
	                // Split?
	                else if(bucketSzs[(size_t)i] > bsz) {
	                    // Add an additional sample from the bucketReps[]
	                    // set accumulated in the binarySASearch loop; this
	                    // effectively splits the bucket
	                    _sampleSuffs.insert(bucketReps[(size_t)i], (TIndexOffU)(i + (added++)));
	                }
	            }
	        }
	        if(added == 0) {
	            //if(this->verbose()) {
	            //	cout << "Final bucket sizes:" << endl;
	            //	cout << "  (begin): " << bucketSzs[0] << " (" << (int)(bsz - bucketSzs[0]) << ")" << endl;
	            //	for(uint32_t i = 1; i < numBuckets; i++) {
	            //		cout << "  " << bucketSzs[i] << " (" << (int)(bsz - bucketSzs[i]) << ")" << endl;
	            //	}
	            //}
	            break;
	        }
	        // Otherwise, continue until no more buckets need to be
	        // split
	        VMSG_NL("Split " << added << ", merged " << merged << "; iterating...");
	    }
	    // Do *not* force a do-over
	    //	if(limit == 0) {
	    //		VMSG_NL("Iterated too many times; trying again...");
	    //		buildSamples();
	    //	}
	    VMSG_NL("Avg bucket size: " << ((double)(len-_sampleSuffs.size()) / (_sampleSuffs.size()+1)) << " (target: " << bsz << ")");
	}
	
	private static long suffixLcp(T t, long aOff, long bOff) {
		TIndexOffU c = 0;
		size_t len = t.length();
		while(aOff + c < len && bOff + c < len && t[aOff + c] == t[bOff + c]) c++;
		return c;
	}
	
	private boolean tieBreakingLcp(long aOff, long bOff, long lcp, boolean lcpIsSoft) {
		const TStr& t = this->text();
		TIndexOffU c = 0;
		TIndexOffU tlen = (TIndexOffU)t.length();
		uint32_t dcDist = _dc.get()->tieBreakOff(aOff, bOff);
		lcpIsSoft = false; // hard until proven soft
		while(c < dcDist &&    // we haven't hit the tie breaker
		      c < tlen-aOff && // we haven't fallen off of LHS suffix
		      c < tlen-bOff && // we haven't fallen off of RHS suffix
		      t[aOff+c] == t[bOff+c]) // we haven't hit a mismatch
			c++;
		lcp = c;
		if(c == tlen-aOff) {
			// Fell off LHS (a), a is greater
			return false;
		} else if(c == tlen-bOff) {
			// Fell off RHS (b), b is greater
			return true;
		} else if(c == dcDist) {
			// Hit a tie-breaker element
			lcpIsSoft = true;
			return _dc.get()->breakTie(aOff+c, bOff+c) < 0;
		} else {
			return t[aOff+c] < t[bOff+c];
		}
	}
	
	public static long lookupSuffixZ(T t, long zOff, long off, EList<Long> z) {
		if(zOff < z.size()) {
			TIndexOffU ret = z[zOff];
			return ret;
		}
		return suffixLcp(t, off + zOff, off);
	}
	
	public boolean suffixCmp(long cmp, long i, long j, long k, boolean kSoft, EList<Long> z) {
		
	}
	
	public void qsort(EList<Long> bucket) {
		String t = this.text();
		TIndexOffU *s = bucket.ptr();
		size_t slen = bucket.size();
		TIndexOffU len = (TIndexOffU)t.length();
		if(_dc.get() != NULL) {
			// Use the difference cover as a tie-breaker if we have it
			VMSG_NL("  (Using difference cover)");
			// Extract the 'host' array because it's faster to work
			// with than the EList<> container
			const uint8_t *host = (const uint8_t *)t.buf();
			assert(_dc.get() != NULL);
			mkeyQSortSufDcU8(t, host, len, s, slen, *_dc.get(), 4,
			                 this->verbose(), this->sanityCheck());
		} else {
			VMSG_NL("  (Not using difference cover)");
			// We don't have a difference cover - just do a normal
			// suffix sort
			mkeyQSortSuf(t, s, slen, 4,
			             this->verbose(), this->sanityCheck());
		}
	}
}
